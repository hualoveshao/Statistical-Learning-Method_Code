{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 感知机存在的问题\n",
    "1. 相差一点点，就完全的说成不同的分类，没有明确制定度量标准，例如相差的小概率差距就小，差距就大。\n",
    "2. sign不可微分，逻辑回归直接跳过了这一步，用力里面的函数进行了梯度下降，此处使用一种可微的函数进行替换。\n",
    "\n",
    "思想就是结合了感知机和条件概率，构造了一个可微的条件概率公式，对条件概率公式，根据最大似然估计估计参数后，用于其他数据的预测，参数只有两个一个是w,一个是b\n",
    "#### 极大似然估计计算w，b，导数等于0对应的w和b就是最优解，由于存在求和，为0求解不好实现，因此使用梯度上升法\n",
    "\n",
    "#### 梯度上升法，求最大值\n",
    "每一个轮次，对所有的数据执行梯度上升，实现时可将w和b合在一起，x做追加1的操作\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from math import *\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 (9000, 965)\n",
      "测试集 (1000, 965)\n"
     ]
    }
   ],
   "source": [
    "#文件预处理成tsv格式\n",
    "def read_file(file_name):\n",
    "    with open(file_name,'r',encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "    label_map = {}\n",
    "    label_map[\"ham\"] = 0\n",
    "    label_map[\"spam\"] = 1\n",
    "    \n",
    "    \n",
    "    text = list()\n",
    "    label = list()\n",
    "    label_num = list()\n",
    "    for item in data:\n",
    "        item = item.strip()\n",
    "        item = item.split(\" \")\n",
    "        item_len = len(item)\n",
    "        tmp_list = list()\n",
    "        if(item[1] in [\"ham\",\"spam\"]):\n",
    "            label.append(item[1])\n",
    "            label_num.append(label_map[item[1]])\n",
    "            for index in range(2,item_len,2):\n",
    "                tmp_list.append(item[index])\n",
    "        text.append(tmp_list)\n",
    "    return text,label,label_num\n",
    "\n",
    "\n",
    "train_text,train_label,train_label_num = read_file(\"../data/train\")\n",
    "test_text,test_label,test_label_num = read_file(\"../data/test\")\n",
    "\n",
    "\n",
    "train_text = [\" \".join(item) for item in train_text]\n",
    "test_text = [\" \".join(item) for item in test_text]\n",
    "\n",
    "\n",
    "\n",
    "cv = CountVectorizer()\n",
    "part_fit = cv.fit(train_text) # 以部分句子为参考\n",
    "train_all_count = cv.transform(train_text) # 对训练集所有邮件统计单词个数\n",
    "test_all_count = cv.transform(test_text) # 对测试集所有邮件统计单词个数\n",
    "tfidf = TfidfTransformer()\n",
    "train_tfidf_matrix = tfidf.fit_transform(train_all_count)\n",
    "test_tfidf_matrix = tfidf.fit_transform(test_all_count)\n",
    "\n",
    "\n",
    "\n",
    "print('训练集', train_tfidf_matrix.shape)\n",
    "print('测试集', test_tfidf_matrix.shape)\n",
    "\n",
    "#训练数据\n",
    "train_tfidf_matrix_1 = train_tfidf_matrix.toarray()\n",
    "#测试数据\n",
    "test_tfidf_matrix1 = test_tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 545)\n"
     ]
    }
   ],
   "source": [
    "#进行降维打击\n",
    "# PCA\n",
    "pca = PCA(n_components=0.9)# 保证降维后的数据保持90%的信息\n",
    "pca.fit(train_tfidf_matrix_1)\n",
    "pca_train_tfidf_matrix_1 = pca.transform(train_tfidf_matrix_1)\n",
    "pca_train_tfidf_matrix_1.shape\n",
    "pca_test_tfidf_matrix_1 = pca.transform(test_tfidf_matrix1)\n",
    "print(pca_train_tfidf_matrix_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建逻辑斯蒂回归模型\n",
    "#执行一步梯度上升\n",
    "def get_data(w,x,y):\n",
    "    wx = (w*x).sum()\n",
    "    return y*x-x*np.exp(wx)/(1+np.exp(wx))\n",
    "\n",
    "#根据训练数据获取w\n",
    "def train_get_parameter(train_data,train_label,iter_num=200):\n",
    "    m,n = train_data.shape\n",
    "    #对数据添加一列\n",
    "    train_data = np.insert(train_data,n,np.ones(m),1)\n",
    "    #初始化w \n",
    "    w = np.zeros(n+1)\n",
    "    #梯度上升法更新w\n",
    "    for i in tqdm(range(iter_num)):\n",
    "        #每一个都执行一下梯度上升，相当于一个batch\n",
    "        for j in range(m):\n",
    "            #返回一个n+1维度的数据\n",
    "            w = w + get_data(w,train_data[j],train_label[j])\n",
    "    return w\n",
    "    \n",
    "\n",
    "\n",
    "#根据w预测每个值的概率\n",
    "def predict(w,test_data):\n",
    "    m,n = test_data.shape\n",
    "    #对test_data进行扩充\n",
    "    test_data = np.insert(test_data,n,np.ones(m),1)\n",
    "    result = list()\n",
    "    #预测\n",
    "    for i in range(m):\n",
    "        pro = 1/(1+np.exp((w*test_data[i]).sum()))\n",
    "        \n",
    "        if(pro>0.5):\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▍                                                  | 75/200 [00:35<01:11,  1.74it/s]"
     ]
    }
   ],
   "source": [
    "w = train_get_parameter(pca_train_tfidf_matrix_1,train_label_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(w,pca_test_tfidf_matrix_1)\n",
    "acc = accuracy_score(result,test_label_num)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
