{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#原始贝叶斯\n",
    "class NaiveBayes:\n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.classes = np.unique(y)\n",
    "#         print(self.classes)\n",
    "        self.parameters = {}\n",
    "        for i , c in enumerate(self.classes):\n",
    "            #计算属于同一类别的均值,方差和各类别的先验概率p(y).\n",
    "            X_index_c  = x[np.where(y == c)]\n",
    "            X_index_c_mean = np.mean(X_index_c, axis=0, keepdims=True)\n",
    "            X_index_c_var = np.var(X_index_c, axis=0, keepdims=True)\n",
    "            parameters = {'mean':X_index_c_mean,'var':X_index_c_var,'prior':X_index_c.shape[0]/ x.shape[0]}\n",
    "            self.parameters['class' + str(c)] = parameters  #字典嵌套\n",
    "#             print(X_index_c.shape[0])\n",
    "        \n",
    "        \n",
    "    def _pdf(self, x, classes):\n",
    "        #用高斯分布拟合p(x|y),也就是后验概率.并且按行每个特征的p(x|y)累乘,取log成为累加.\n",
    "        eps = 1e-4  #防止分母为0\n",
    "        mean = self.parameters['class' + str(classes)]['mean']\n",
    "        var  = self.parameters['class' + str(classes)]['var']\n",
    "        fenzi = np.exp(-(x - mean) ** 2 / (2 * (var) ** 2 + eps))\n",
    "        fenmu = (2 * np.pi) ** 0.5 * var + eps\n",
    "        result = np.sum(np.log(fenzi / fenmu), axis=1, keepdims=True)\n",
    "        #print(result.T.shape)\n",
    "        return result.T #(1, 719)\n",
    "       \n",
    "        \n",
    "    def _predict(self, x):\n",
    "        # 计算每个种类的p(y)p(x|y)\n",
    "        output = []\n",
    "        for y in range(self.classes.shape[0]):\n",
    "            prior = np.log(self.parameters['class' + str(y)]['prior'])\n",
    "            posterior = self._pdf(x, y)\n",
    "            prediction = prior + posterior\n",
    "            output.append(prediction)\n",
    "        return output\n",
    "        \n",
    "    def predict(self, x):\n",
    "        #argmax(p(y)p(x|y))就是最终的结果\n",
    "        output = self._predict(x)\n",
    "        output = np.reshape(output, (self.classes.shape[0], x.shape[0]))\n",
    "        prediction = np.argmax(output, axis=0)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 (9000, 453)\n",
      "测试集 (1000, 453)\n",
      "原始贝叶斯混淆矩阵:\n",
      " [[324  96]\n",
      " [  1 579]]\n",
      "原始贝叶斯准确率：\n",
      " 0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huarui\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#文件预处理成tsv格式\n",
    "def read_file(file_name):\n",
    "    with open(file_name,'r',encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "    label_map = {}\n",
    "    label_map[\"ham\"] = 0\n",
    "    label_map[\"spam\"] = 1\n",
    "    \n",
    "    \n",
    "    text = list()\n",
    "    label = list()\n",
    "    label_num = list()\n",
    "    for item in data:\n",
    "        item = item.strip()\n",
    "        item = item.split(\" \")\n",
    "        item_len = len(item)\n",
    "        tmp_list = list()\n",
    "        if(item[1] in [\"ham\",\"spam\"]):\n",
    "            label.append(item[1])\n",
    "            label_num.append(label_map[item[1]])\n",
    "            for index in range(2,item_len,2):\n",
    "                tmp_list.append(item[index])\n",
    "        text.append(tmp_list)\n",
    "    return text,label,label_num\n",
    "\n",
    "\n",
    "train_text,train_label,train_label_num = read_file(\"../data/train\")\n",
    "test_text,test_label,test_label_num = read_file(\"../data/test\")\n",
    "\n",
    "\n",
    "train_text = [\" \".join(item) for item in train_text]\n",
    "test_text = [\" \".join(item) for item in test_text]\n",
    "\n",
    "\n",
    "\n",
    "cv = CountVectorizer(min_df = 512)\n",
    "part_fit = cv.fit(train_text) # 以部分句子为参考\n",
    "train_all_count = cv.transform(train_text) # 对训练集所有邮件统计单词个数\n",
    "test_all_count = cv.transform(test_text) # 对测试集所有邮件统计单词个数\n",
    "tfidf = TfidfTransformer()\n",
    "train_tfidf_matrix = tfidf.fit_transform(train_all_count)\n",
    "test_tfidf_matrix = tfidf.fit_transform(test_all_count)\n",
    "\n",
    "\n",
    "\n",
    "print('训练集', train_tfidf_matrix.shape)\n",
    "print('测试集', test_tfidf_matrix.shape)\n",
    "\n",
    "#训练\n",
    "train_tfidf_matrix_1 = train_tfidf_matrix.toarray()\n",
    "mnb = NaiveBayes()\n",
    "mnb.fit(train_tfidf_matrix_1, train_label_num)\n",
    "#预测\n",
    "test_tfidf_matrix1 = test_tfidf_matrix.toarray()\n",
    "pred_test_label_num = mnb.predict(test_tfidf_matrix1)\n",
    "#混淆矩阵输出\n",
    "c_m = confusion_matrix(test_label_num, pred_test_label_num, labels=None, sample_weight=None)\n",
    "print(\"原始贝叶斯混淆矩阵:\\n\",c_m)\n",
    "print(\"原始贝叶斯准确率：\\n\",accuracy_score(test_label_num, pred_test_label_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
